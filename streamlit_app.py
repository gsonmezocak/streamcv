import streamlit as st
import google.generativeai as genai
import firebase_admin
from firebase_admin import credentials, firestore, auth
import pyrebase
import json
import numpy as np
import re
import time
import concurrent.futures
import pandas as pd
import fitz  # PyMuPDF
from docx import Document
import io

# --- 0. SAYFA AYARLARI ---
# HTML dosyalarÄ±nÄ±zdaki fontlarÄ± ve iconlarÄ± ekliyoruz
st.set_page_config(
    page_title="AI Powered CV Matching",
    page_icon="ðŸ¤–",
    layout="wide"
)

st.markdown("""
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;700;900&display=swap" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        /* Streamlit'in radio butonunu sign_up.html'deki toggle'a benzetme */
        div[role="radiogroup"] {
            background-color: #F0F0F0;
            border-radius: 0.5rem;
            padding: 0.25rem;
            display: flex;
        }
        div[role="radiogroup"] label {
            background-color: transparent;
            color: #6B7280;
            flex-grow: 1;
            text-align: center;
            padding: 0.5rem;
            border-radius: 0.375rem;
            transition: all 0.2s ease-in-out;
        }
        /* SeÃ§ili olan radio butonu */
        div[role="radiogroup"] input:checked + div {
            background-color: #FFFFFF;
            color: #111827;
            box-shadow: 0 1px 3px 0 rgba(0, 0, 0, 0.1), 0 1px 2px 0 rgba(0, 0, 0, 0.06);
        }
        .material-symbols-outlined {
            font-variation-settings: 'FILL' 0, 'wght' 400, 'GRAD' 0, 'opsz' 48;
            vertical-align: middle;
        }
    </style>
""", unsafe_allow_html=True)


# --- 1. FIREBASE ADMIN BAÄžLANTISI ---
@st.cache_resource
def init_firebase_admin():
    try:
        creds_dict = dict(st.secrets["firebase_credentials"])
        creds_dict["private_key"] = creds_dict["private_key"].replace(r'\n', '\n')
        creds = credentials.Certificate(creds_dict)
        firebase_admin.initialize_app(creds)
    except ValueError:
        pass  
    except Exception as e:
        st.error(f"ðŸ”¥ FÄ°REBASE ADMÄ°N HATASI: {e}")
        st.stop()
    return firestore.client()

# --- 2. FIREBASE AUTH BAÄžLANTISI ---
@st.cache_resource
def init_firebase_auth():
    try:
        firebase_config = {
            "apiKey": st.secrets["FIREBASE_WEB_API_KEY"],
            "authDomain": f"{st.secrets['firebase_credentials']['project_id']}.firebaseapp.com",
            "projectId": st.secrets['firebase_credentials']['project_id'],
            "storageBucket": f"{st.secrets['firebase_credentials']['project_id']}.appspot.com",
            "databaseURL": f"https://{st.secrets['firebase_credentials']['project_id']}-default-rtdb.firebaseio.com",
        }
        firebase = pyrebase.initialize_app(firebase_config)
        return firebase.auth()
    except Exception as e:
        st.error(f"ðŸ”¥ FÄ°REBASE AUTH HATASI: {e}")
        st.stop()

# --- 3. GEMINI AI BAÄžLANTISI ---
@st.cache_resource
def init_gemini():
    try:
        genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
        generation_config = genai.types.GenerationConfig(response_mime_type="application/json")
        analysis_model = genai.GenerativeModel('models/gemini-flash-latest', generation_config=generation_config)
        embedding_model = genai.GenerativeModel('models/text-embedding-004')
        return analysis_model, embedding_model
    except Exception as e:
        st.error(f"ðŸ’Ž GEMÄ°NÄ° BAÄžLATMA HATASI: {e}")
        st.stop()

# --- UYGULAMA BAÅžLANGICI ---
try:
    db = init_firebase_admin()
    auth_client = init_firebase_auth()
    gemini_model, embedding_model = init_gemini()
except Exception as e:
    st.error("Uygulama baÅŸlatÄ±lÄ±rken kritik bir hata oluÅŸtu.")
    st.stop()

# --- OTURUM YÃ–NETÄ°MÄ° ---
if 'user_email' not in st.session_state:
    st.session_state['user_email'] = None
if 'user_token' not in st.session_state:
    st.session_state['user_token'] = None

# --- YARDIMCI FONKSÄ°YONLAR ---

@st.cache_data(ttl=300) 
def get_platform_stats():
    try:
        job_docs = db.collection("job_postings").stream()
        total_jobs = sum(1 for _ in job_docs)
        profile_docs = db.collection("user_profiles").stream()
        total_profiles = sum(1 for _ in profile_docs)
        return total_jobs, total_profiles
    except Exception as e:
        return 0, 0

@st.cache_data(ttl=3600) 
def get_total_user_count():
    try:
        page = auth.list_users()
        all_users = list(page.iterate_all())
        return len(all_users)
    except Exception as e:
        return 0

@st.cache_data(ttl=300) 
def get_job_postings_with_vectors():
    jobs = []
    try:
        docs = db.collection("job_postings").stream()
        for doc in docs:
            job_data = doc.to_dict()
            if 'vector' in job_data: 
                jobs.append({
                    "id": doc.id,
                    "title": job_data.get("title", "No Title"),
                    "description": job_data.get("description", "No Description"),
                    "vector": job_data.get("vector")
                })
        return jobs
    except Exception as e:
        st.error(f"Ä°ÅŸ ilanlarÄ± Ã§ekilirken hata oluÅŸtu: {e}")
        return []

def get_gemini_analysis(cv, job_post):
    prompt = f"""
    You are a senior Human Resources (HR) specialist.
    Analyze the following CV and JOB POSTING.
    
    Your response MUST be a valid JSON object with the following exact structure:
    {{
        "score": <number from 0-100>,
        "pros": ["<strength 1>", "<strength 2>", "<strength 3>"],
        "cons": ["<weakness 1>", "<weakness 2>", "<weakness 3>"],
        "summary": "<A 2-3 sentence evaluation summary>"
    }}

    ---[CV TEXT]----
    {cv}
    -----------------

    ---[JOB POSTING TEXT]---
    {job_post}
    -----------------
    """
    try:
        response = gemini_model.generate_content(prompt)
        clean_json_text = re.sub(r"^```json\n", "", response.text)
        clean_json_text = re.sub(r"\n```$", "", clean_json_text).strip()
        analysis_data = json.loads(clean_json_text)
        return analysis_data
    except Exception as e:
        print(f"JSON Parse HatasÄ±: {e}")
        print(f"AI Ham YanÄ±tÄ±: {response.text}")
        return None 

def get_embedding(text):
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=text,
            task_type="RETRIEVAL_DOCUMENT"
        )
        return result['embedding']
    except Exception as e:
        st.error(f"Metnin 'parmak izi' alÄ±nÄ±rken hata oluÅŸtu: {e}")
        return None

def get_user_profile(user_id):
    """(GÃœNCELLENDÄ°) Sadece CV'yi deÄŸil, tÃ¼m profili Ã§eker."""
    try:
        doc_ref = db.collection("user_profiles").document(user_id).get()
        if doc_ref.exists:
            return doc_ref.to_dict()
        return {} # BoÅŸ bir sÃ¶zlÃ¼k dÃ¶ndÃ¼r
    except Exception as e:
        st.error(f"Profiliniz Ã§ekilirken hata oluÅŸtu: {e}")
        return {}

def parse_cv_file(file_bytes, file_name):
    """(YENÄ°) YÃ¼klenen PDF veya DOCX dosyasÄ±nÄ± metne Ã§evirir."""
    text = ""
    try:
        if file_name.endswith('.pdf'):
            with fitz.open(stream=file_bytes, filetype="pdf") as doc:
                for page in doc:
                    text += page.get_text()
        elif file_name.endswith('.docx'):
            doc = Document(io.BytesIO(file_bytes))
            for para in doc.paragraphs:
                text += para.text + "\n"
        else:
            # DiÄŸer dosya tÃ¼rlerini (Ã¶rn. .txt) basitÃ§e okumayÄ± dene
            text = file_bytes.decode('utf-8')
            
        return text
    except Exception as e:
        st.error(f"Dosya okunurken hata oluÅŸtu: {e}")
        return None

# --- ANA UYGULAMA FONKSÄ°YONU ---
def main_app():
    
    col1, col2 = st.columns([0.8, 0.2])
    with col1:
        st.title("ðŸ¤– AI CV Matching Platform")
    with col2:
        st.write(f"`{st.session_state['user_email']}`")
        if st.button("Logout", use_container_width=True):
            st.session_state['user_email'] = None
            st.session_state['user_token'] = None
            st.rerun()  
            
    st.markdown("---") 

    with st.spinner("Platform istatistikleri yÃ¼kleniyor..."):
        total_jobs, total_profiles = get_platform_stats()
        total_users = get_total_user_count()
    
    stat_col1, stat_col2, stat_col3 = st.columns(3)
    with stat_col1:
        st.metric(label="ðŸ‘¥ Toplam KayÄ±tlÄ± KullanÄ±cÄ±", value=total_users)
    with stat_col2:
        st.metric(label="ðŸŽ¯ Toplam Ä°ÅŸ Ä°lanÄ±", value=total_jobs)
    with stat_col3:
        st.metric(label="ðŸ‘¤ KayÄ±tlÄ± CV Profili", value=total_profiles, help="CV'sini kaydeden kullanÄ±cÄ± sayÄ±sÄ±.")

    st.markdown("---")
    
    user_id = auth_client.get_account_info(st.session_state['user_token'])['users'][0]['localId']

    tab1, tab2, tab3 = st.tabs(["ðŸš€ Auto-Matcher", "ðŸ“ Ä°lan YÃ¶netimi", "ðŸ‘¤ Profilim"])

    # --- (GÃœNCELLENDÄ°) Sekme 1: Auto-Matcher ---
    with tab1:
        st.header("CV'niz iÃ§in En Ä°yi Ä°ÅŸleri Bulun")
        
        # CV'yi profilden Ã§ek
        profile = get_user_profile(user_id)
        cv_text = profile.get("cv_text")
        
        if not cv_text:
            st.warning("HenÃ¼z kayÄ±tlÄ± bir CV'niz bulunmuyor.")
            st.info("LÃ¼tfen Ã¶nce 'ðŸ‘¤ Profilim' sekmesine gidin ve CV'nizi yÃ¼kleyin.")
            st.stop()
            
        st.success("Harika! 'Profilim' sekmesinde kayÄ±tlÄ± olan CV'niz kullanÄ±lacak.")
        st.markdown(f"> **Profil BaÅŸlÄ±ÄŸÄ±nÄ±z:** `{profile.get('headline', 'BelirtilmemiÅŸ')}`")
        
        CANDIDATE_POOL_SIZE = 10 
        TOP_N_RESULTS = 5       
        
        if st.button(f"En Ä°yi {TOP_N_RESULTS} EÅŸleÅŸmeyi Bul", type="primary", use_container_width=True):
            start_time = time.time() 
            
            # --- AdÄ±m 1: HÄ±zlÄ± Filtreleme (VektÃ¶r Arama) ---
            with st.spinner(f"AdÄ±m 1/3: TÃ¼m ilanlar taranÄ±yor..."):
                all_jobs = get_job_postings_with_vectors()
                if not all_jobs:
                    st.warning("HiÃ§ iÅŸ ilanÄ± bulunamadÄ±. LÃ¼tfen Ã¶nce ilan ekleyin.")
                    st.stop()
                
                cv_vector = get_embedding(cv_text)
                if not cv_vector:
                    st.error("CV'niz iÃ§in 'parmak izi' oluÅŸturulamadÄ±. Ä°ÅŸlem iptal edildi.")
                    st.stop()
                        
                job_vectors = np.array([job['vector'] for job in all_jobs])
                cv_vector_np = np.array(cv_vector)
                similarities = np.dot(job_vectors, cv_vector_np)
                
                pool_size = min(len(all_jobs), CANDIDATE_POOL_SIZE)
                top_candidate_indices = np.argsort(similarities)[-pool_size:][::-1]

            # --- AdÄ±m 2: Paralel Analiz ---
            analysis_results = []
            progress_bar = st.progress(0, text=f"AdÄ±m 2/3: En iyi {pool_size} aday analiz ediliyor... (0%)") 

            with concurrent.futures.ThreadPoolExecutor(max_workers=pool_size) as executor:
                future_to_job = {}
                for index in top_candidate_indices:
                    matched_job = all_jobs[index]
                    future = executor.submit(get_gemini_analysis, cv_text, matched_job['description'])
                    future_to_job[future] = matched_job
                
                completed_count = 0
                for future in concurrent.futures.as_completed(future_to_job):
                    matched_job = future_to_job[future]
                    try:
                        analysis_data = future.result() 
                        if analysis_data and analysis_data.get("score") is not None:
                            analysis_results.append({
                                "job": matched_job,
                                "data": analysis_data,
                                "score": int(analysis_data.get("score", 0))
                            })
                    except Exception as e:
                        st.error(f"'{matched_job['title']}' ilanÄ± analiz edilirken hata: {e}")
                    
                    completed_count += 1
                    percent_complete = completed_count / pool_size
                    progress_bar.progress(percent_complete, text=f"AdÄ±m 2/3: Analiz ediliyor... {int(percent_complete * 100)}% tamamlandÄ±") 
            
            progress_bar.empty()

            # --- AdÄ±m 3: Yeniden SÄ±rala ve GÃ¶ster ---
            with st.spinner(f"AdÄ±m 3/3: SonuÃ§lar sÄ±ralanÄ±yor..."):
                if not analysis_results:
                    st.error("AI analizi tÃ¼m adaylar iÃ§in baÅŸarÄ±sÄ±z oldu. LÃ¼tfen tekrar deneyin.")
                    st.stop()

                sorted_results = sorted(analysis_results, key=lambda x: x["score"], reverse=True)
                
                end_time = time.time()
                st.success(f"Ä°ÅŸlem tamam! En iyi {TOP_N_RESULTS} eÅŸleÅŸme {end_time - start_time:.2f} saniyede bulundu.")
                st.balloons() 
                
                st.markdown("---")

                for i, result in enumerate(sorted_results[:TOP_N_RESULTS]):
                    rank = i + 1
                    job_title = result["job"]["title"]
                    score = result["score"]
                    analysis_data = result["data"]
                    
                    with st.container(border=True):
                        col_metric, col_details = st.columns([0.2, 0.8])
                        with col_metric:
                            st.metric(label=f"#{rank} EÅŸleÅŸme", value=f"{score}%")
                        with col_details:
                            st.subheader(job_title)
                            with st.expander("DetaylÄ± AI analizini gÃ¶rmek iÃ§in tÄ±klayÄ±n"):
                                st.subheader("Ã–zet")
                                st.write(analysis_data.get("summary", "N/A"))
                                st.subheader("GÃ¼Ã§lÃ¼ YÃ¶nler (ArtÄ±lar)")
                                pros = analysis_data.get("pros", [])
                                if pros:
                                    for pro in pros: st.markdown(f"* {pro}")
                                else:
                                    st.write("N/A") 
                                st.subheader("ZayÄ±f YÃ¶nler (Eksiler)")
                                cons = analysis_data.get("cons", [])
                                if cons:
                                    for con in cons: st.markdown(f"* {con}")
                                else:
                                    st.write("N/A")
                    st.divider()

    # --- Sekme 2: Ä°lan YÃ¶netimi (Toplu YÃ¼kleme dahil) ---
    with tab2:
        st.header("Job Management")
        
        # Tekli ilan formu
        with st.form("new_job_form", clear_on_submit=True):
            st.subheader("Tek Ä°ÅŸ Ä°lanÄ± Ekle")
            job_title = st.text_input("Ä°ÅŸ BaÅŸlÄ±ÄŸÄ±")
            job_description = st.text_area("Ä°ÅŸ TanÄ±mÄ±", height=200)
            submitted = st.form_submit_button("Ä°lanÄ± Kaydet & VektÃ¶r OluÅŸtur")
            
            if submitted:
                if job_title and job_description:
                    with st.spinner("AI 'parmak izi' (vektÃ¶r) oluÅŸturuluyor..."):
                        job_vector = get_embedding(f"Title: {job_title}\n\nDescription: {job_description}")
                    if job_vector:
                        try:
                            db.collection("job_postings").document().set({
                                "title": job_title,
                                "description": job_description,
                                "created_at": firestore.SERVER_TIMESTAMP,
                                "vector": job_vector,
                                "added_by": st.session_state['user_email']
                            })
                            st.success(f"'{job_title}' baÅŸarÄ±yla eklendi!")
                            st.cache_data.clear() 
                        except Exception as e: st.error(f"Firebase'e kaydederken hata: {e}")
                    else: st.error("AI 'parmak izi' oluÅŸturulamadÄ±.")
                else: st.warning("LÃ¼tfen her iki alanÄ± da doldurun.")

        st.divider()
        
        # Toplu ilan yÃ¼kleme
        st.subheader("VEYA... CSV/Excel ile Toplu Ä°lan YÃ¼kle")
        st.markdown("**'title'** ve **'description'** sÃ¼tunlarÄ±nÄ± iÃ§eren bir dosya yÃ¼kleyin.")
        
        uploaded_file = st.file_uploader("Bir CSV veya Excel dosyasÄ± seÃ§in", type=["csv", "xlsx"])
        
        if uploaded_file is not None:
            try:
                if uploaded_file.name.endswith('.csv'):
                    df = pd.read_csv(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)

                if 'title' not in df.columns or 'description' not in df.columns:
                    st.error("Hata: Dosya 'title' ve 'description' sÃ¼tunlarÄ±nÄ± iÃ§ermelidir.")
                else:
                    st.success(f"'{uploaded_file.name}' dosyasÄ± okundu. {len(df)} ilan bulundu.")
                    st.dataframe(df.head())
                    
                    if st.button(f"{len(df)} Ä°lanÄ± Ä°ÅŸle ve YÃ¼kle", type="primary"):
                        st.info("Toplu yÃ¼kleme baÅŸlÄ±yor... Bu iÅŸlem birkaÃ§ dakika sÃ¼rebilir.")
                        progress_bar_bulk = st.progress(0, text="BaÅŸlatÄ±lÄ±yor...")
                        success_count = 0
                        batch = db.batch()
                        
                        for index, row in df.iterrows():
                            title = str(row['title'])
                            description = str(row['description'])
                            
                            progress_text = f"Ä°ÅŸleniyor ({index + 1}/{len(df)}): {title[:30]}..."
                            progress_bar_bulk.progress((index + 1) / len(df), text=progress_text)
                            
                            job_vector = get_embedding(f"Title: {title}\n\nDescription: {description}")
                            
                            if job_vector:
                                doc
